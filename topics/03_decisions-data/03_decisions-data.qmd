---
title: "Decisions and Data"
subtitle: "DATA 5600 Introduction to Regression and Machine Learning for Analytics"
author: Marc Dotson
title-slide-attributes:
  data-background-color: "#0F2439"
format: 
  revealjs:
    theme: ../slides.scss # Modified slides theme.
    slide-number: c/t     # Numbered slides current/total.
    self-contained: true  # Render to a single HTML file.
execute:
  eval: false
  echo: true
jupyter: python3
---

## {background-color="#288DC2"}

### Get Started {.permanent-marker-font}

#### Last Time

- Walked through a high-level overview of our modeling workflow

#### Preview

- Discuss decision-making in the presence of uncertainty
- Start modeling data generating processes

## {background-color="#D1CBBD"}

::: {.columns .v-center}
![](../../figures/workflow_plan-build.png){fig-align="center"}
:::

## 

:::: {.columns .v-center}

::: {.column width="40%"}
![](../../figures/image_cellphone.png){fig-align="center"}
:::

::: {.column width="60%"}
::: {.incremental}
- International cell phone carrier optimizing their product line
- Refused to narrow their focus and limit the scope of the problem
- The more **specific the questions** the more **specific the answers**
:::
:::

::::

# Decision-Making in the Presence of Uncertainty

## Specify the business objective and scope

Informing business decision-making requires a **clear objective** and **limited scope**

::: {.incremental}
- Communicate with domain experts and stakeholders
- Research the industry and relevant literature
- Learn the business model and the industry jargon
:::

::: {.fragment}
What business objective are you considering for your project? Is it specific?
:::

## Most decision-making is informal

How did you decide on your major?

:::: {.columns}

::: {.column width="50%"}
::: {.fragment fragment-index=1}
**Pros**
:::

::: {.incremental}
- Bridge between ML and business
- Practical, hands-on work
- Marketable, hard skillset
- Application for ML
- Good job prospects
- Interdisciplinary
:::
:::

::: {.column width="50%"}
::: {.fragment fragment-index=2}
**Cons**
:::

::: {.incremental}
- Rapidly changing field
- Tradeoff on theoretical depth
- Interdisciplinary
:::
:::

::::

::: {.fragment .fade-up .h-center}
### We can do better!
:::

## Start by identifying actions and states

When making a decision, we need to consider what **actions** we can take and the possible relevant **states of the world**

::: {.fragment}
We can organize this information into a decision matrix (i.e., a **loss** or **payoff/utility** matrix), assuming we know the outcomes
:::

:::: {.columns}

::: {.column width="60%"}
::: {.fragment}
|             | **States** |             |
|-------------|------------|-------------|
| **Actions** | Low Demand | High Demand |
| Go          | -\$20,000  | \$70,000    |
| No-Go       | \$0.00     | \$0.00      |
:::
:::

::: {.column width="40%"}
::: {.incremental}
- If demand is low, what action should we take?
- If demand is high, what action should we take?
:::
:::

::::

## How do we include uncertainty?

We don't know the state of the world, but let's assume the probability of demand is 10% Low, 60% Medium, and 30% High

|                 | **States** |            |            |
|-----------------|------------|------------|------------|
| **Actions**     | Low        | Medium     | High       |
| Price at \$4.00 | -\$20,000  | \$30,000   | \$70,000   |
| Price at \$3.50 | -\$15,000  | \$25,000   | \$75,000   |
| Price at \$3.00 | -\$10,000  | \$20,000   | \$80,000   |
| No-Go           | \$0.00     | \$0.00     | \$0.00     |

## How do we include uncertainty? {visibility="uncounted"}

We don't know the state of the world, but let's assume the probability of demand is 10% Low, 60% Medium, and 30% High

|                 | **States** |            |            |            |
|-----------------|------------|------------|------------|------------|
| **Actions**     | Low        | Medium     | High       |            |
| Price at \$4.00 | -\$20,000  | \$30,000   | \$70,000   | *\$44,000* |
| Price at \$3.50 | -\$15,000  | \$25,000   | \$75,000   | *\$43,500* |
| Price at \$3.00 | -\$10,000  | \$20,000   | \$80,000   | *\$43,000* |
| No-Go           | \$0.00     | \$0.00     | \$0.00     | *\$0.00*   |

::: {.fragment}
$$
\LARGE{\sum \ell(a, s) p(s)}
$$
:::

## Decision theory provides a formal framework

**Decision theory** (a.k.a., **decision science**) provides a principled, unifying framework for informing decision-making in the presence of uncertainty

:::: {.columns}

::: {.column width="50%"}
::: {.fragment}
$$
\LARGE{\ell(a, s)}
$$
:::
:::

::: {.column width="50%"}
::: {.incremental}
- $\ell()$ is a **loss function**
- $a$ are **actions** we can take
- $s$ are **states of the world**
:::
:::

::::

## Decision theory provides a formal framework {visibility="uncounted"}

**Decision theory** (a.k.a., **decision science**) provides a principled, unifying framework for informing decision-making in the presence of uncertainty

:::: {.columns}

::: {.column width="50%"}
$$
\LARGE{\color{grey}{\ell(a, }\theta\color{grey}{)}}
$$
:::

::: {.column width="50%"}
- $\ell()$ is a **loss function**
- $a$ are **actions** we can take
- $s$ are **states of the world**
- $\theta$ represents **unknowns**
:::

::::

::: {.fragment}
Many decisions are made informally or using predictive rather than decision theoretic criteria, but when should we use informal vs. formal decision-making?
:::

## Quadratic loss

**Quadratic loss** or **squared error loss** is a commonly used loss function, especially for budgeting, forecasting, and production planning

$$
\LARGE{\ell(a, \theta) = (a - \theta)^2}
$$

::: {.incremental}
- Quadratic loss is **symmetric**: Gains and losses are treated the same
- Large deviations produce more loss than small deviations
:::

## Linear utility

Instead of minimizing loss, we can also maximize a **payoff** or **utility function**, with **linear utility** commonly used

$$
\begin{aligned}
\LARGE{u(a, \theta)} & \hspace{3mm} \LARGE{= -\ell(a, \theta)}
\end{aligned}
$$

## Linear utility {visibility="uncounted"}

Instead of minimizing loss, we can also maximize a **payoff** or **utility function**, with **linear utility** commonly used

$$
\begin{aligned}
\LARGE{u(a, \theta)} & \hspace{3mm} \LARGE{= -\ell(a, \theta)} \\
& \hspace{3mm} \LARGE{= r + c \theta}
\end{aligned}
$$

## Linear utility {visibility="uncounted"}

Instead of minimizing loss, we can also maximize a **payoff** or **utility function**, with **linear utility** commonly used

$$
\begin{aligned}
\LARGE{u(a, \theta)} & \hspace{3mm} \LARGE{= -\ell(a, \theta)} \\
& \hspace{3mm} \LARGE{= r + c \theta} \\
& \hspace{3mm} \LARGE{= \theta (r - c)} \\
\end{aligned}
$$

## Linear utility {visibility="uncounted"}

Instead of minimizing loss, we can also maximize a **payoff** or **utility function**, with **linear utility** commonly used

$$
\begin{aligned}
\LARGE{u(a, \theta)} & \hspace{3mm} \LARGE{\color{grey}{= -\ell(a, \theta)}} \\
& \hspace{3mm} \LARGE{\color{grey}{= r + c \theta}} \\
& \hspace{3mm} \LARGE{= \theta (r - c)}
\end{aligned}
$$

::: {.incremental}
- Our **profit function** $\mathcal{P}(p, \mathcal{D}) = \mathcal{D}(p) \times (p - c)$ is a linear utility function
- Linear utility is also **symmetric** and assumes the decision-maker is **risk neutral**
:::

# What actions, states of the world, and loss/utility function might be relevant for your project? Make it specific. {background-color="#006242"}

# Data Generating Processes

## Decision-making motivates modeling data

In order to inform our decision-making, we need a model to **extract information** from data about the unknown state of the world $\theta$

:::: {.columns}

::: {.column width="50%"}
::: {.fragment}
![](../../figures/models_all-02.png){fig-align="center"}
:::
:::

::: {.column width="50%"}
::: {.incremental}
- Why should we use an **interpretable model** for this problem?
- When would a flexible, **black-box model** be appropriate?
- Why would we need a **causal model**?
:::
:::

::::

## Narrate the data story

All data come from somewhere and narrating the **data generating process** will help you identify the ideal data

::: {.incremental}
- Communicate with domain experts and stakeholders
- Research the industry and relevant literature
- Learn the business model and the industry jargon
:::

::: {.fragment}
Every model is a **simplification of reality**, but the goal is to capture the essence of the data generating process
:::

::: {.fragment}
What data story are you considering for your project? Is it simple *enough*?
:::

## 

::: {.v-center}
![](../../figures/models_rockets.png){fig-align="center"}
:::

## Identify $y$ and $X$

For **supervised learning** we want to learn a **mapping function** from inputs to output $f: X \rightarrow y$, so start translating the data story into a model by identifying the outcome and predictor variables

:::: {.columns}

::: {.column width="50%"}
$y$

- output
- outcome
- response
- dependent variable
- continuous for **regression**
- discrete for **classification**
:::

::: {.column width="50%"}
$X$

- inputs
- features
- predictors
- independent variables
- explanatory variables
- continuous and discrete
:::

::::

## Draw the relationships between $y$ and $X$

It's helpful to draw the possible data generating process as a **graph** where

- Each node is a variable
- Each edge is an association

![](../../figures/dag.png){fig-align="center"}

::: {.fragment}
In DATA 5620, we use this **directed acyclic graph** (DAG) to identify causal effects
:::

## Assume a functional form

Unless we know a lot about the data generating process, we should start with a functional form that makes few assumptions, like a **linear model**

$$
\Large{f(X, \theta) = \theta_0 + \theta_1 x_1 + \cdots + \theta_p x_p + \epsilon}
$$

## Assume a functional form {visibility="uncounted"}

Unless we know a lot about the data generating process, we should start with a functional form that makes few assumptions, like a **linear model**

$$
\Large{f(X, \beta) = \beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p + \epsilon}
$$

::: {.incremental}
- $\beta$ is the **weights** or **parameters** of the mapping function, with $\beta_0$ the **intercept** or **bias** and $\beta_1$ through $\beta_p$ the **slopes**
- $\epsilon$ represents **error**, showing that our model isn't capturing everything about the data generating process
- typically $\epsilon \sim \text{Normal}(0, \sigma^2)$
:::

## Simulate data

We can pretend our model *is* the data generation process and **simulate data** (i.e., generate data) to prepare our analysis and test code

```{python}
#| code-line-numbers: "|1|3-4|6-7|8|9|10|11|12|14"
#| eval: true

import numpy as np

# Set randomization seed
rng = np.random.default_rng(42)

# Specify a function to simulate data
def sim_data(n, beta_0, beta_x1, beta_x2, sigma):
    x1 = rng.normal(10, 3, size=n)
    x2 = rng.binomial(1, 0.5, size=n)
    error = rng.normal(0, sigma, size=n)
    y = beta_0 + beta_x1 * x1 + beta_x2 * x2 + error
    return y, x1, x2

sim_data(n = 5, beta_0 = 2, beta_x1 = -0.3, beta_x2 = 4, sigma = 5)
```

# What might $y$, $X$, and their relationships be for your project? Try drawing a graph. Keep it simple.{background-color="#006242"}

# Uncertainty

## Uncertainty motivates using probability

If decision-making motivates modeling data, **quantifying uncertainty** motivates using **probability**, the mathematical language of uncertainty

::: {.fragment}
What kind of uncertainty?
:::

::: {.incremental}
- **Data uncertainty** or **aleatoric uncertainty** (from the Latin word for dice) is about the information or **signal** we want to extract being obscured by randomness or noise in the data
- **Model uncertainty** or **epistemic uncertainty** (from the study of knowledge) is about our **limited knowledge** of the data generating process
:::

::: {.fragment}
For interpretable models, we **assume a mapping function exists** and try and to carefully build one so we can focus on quantifying uncertainty by estimating parameters
:::

## 

::: {.v-center}
![](../../figures/meme_uncertainty.png){fig-align="center"}
:::

## {background-color="#006242"}

### Exercise 03 {.lato-font}

1. Simulate sales data (not units sold) as a function of four or more predictors
2. Instead of `y`, `x1`, etc. use meaningful variable names
3. Assume the error is distributed normal
4. Use different parameter values than we did in class
5. Comment your code clearly
6. Visualize the simulated data using at least two different plots
7. Submit your code and printed output as a PDF on Canvas

## {background-color="#288DC2"}

### Wrap Up {.permanent-marker-font}

#### Summary

- Discussed decision-making under uncertainty
- Started modeling data generating processes

#### Next Time

- Finish building models using probability
- Demonstrate fitting models to recover parameters

