---
title: "Multilevel Models"
subtitle: "DATA 5600 Introduction to Regression and Machine Learning for Analytics"
author: Marc Dotson
title-slide-attributes:
  data-background-color: "#0F2439"
format: 
  revealjs:
    theme: ../slides.scss  # Modified slides theme
    code-copy: true        # Show code blocks copy button
    slide-number: c/t      # Numbered slides current/total
    embed-resources: true  # Render to a single HTML file
execute:
  eval: false
  echo: true
jupyter: python3
---

## {background-color="#288DC2"}

### Get Started {.permanent-marker-font}

#### Last Time

- Introduced two-way and higher-order interactions
- Started motivating multilevel models using interactions

#### Preview

- Finish introducing multilevel models
- Summarize decision-making under uncertainty
- Discuss project expectations

## {background-color="#D1CBBD"}

::: {.columns .v-center}
![](../../figures/workflow_build-predict.png){fig-align="center"}
:::

# Adaptive Regularization

## Multilevel logistic regression

$$
\large{y_i \sim \text{Binomial}(1, p_i)} \\
\large{\log\left({p_i \over 1 - p_i}\right) = \beta_{0,h} + \beta_{1,h} x_{1,i} + \cdots + \beta_{p,h} x_{p,i}}
$$

::: {.incremental}
- The $h$ index references the **group** that observation $i$ belongs to
- We can condition the intercept $\beta_{0,h}$, slopes $\beta_{j,h}$, or both by group
- This allows us to capture **heterogeneous effects** across groups
- Estimating Bayesian multilevel models not only includes regularization, it includes **adaptive regularization** via partial pooling
:::

## 

:::: {.columns .v-center .h-center}

::: {.column width="33.33%"}
**Complete pooling**

Groups have the same parameters from one model
:::

::: {.fragment fragment-index=3 .column width="33.33%"}
**Partial pooling**

Each group has their own parameters but they **pool information** in one model
:::

::: {.fragment fragment-index=2 .column width="33.33%"}
**No pooling**

Each group has their own parameters from separate models
:::

::::

## 

::: {.v-center}

$$
\LARGE{p(\theta | X, Y) \propto p(X, Y | \theta) \ p(\theta)}
$$
:::

## 

::: {.v-center}

$$
\LARGE{p(\theta, \alpha | X, Y) \propto p(X, Y | \theta) \ \color{red}{p(\theta | \alpha)} \ p(\alpha)}
$$
:::

## 

::: {.v-center}
![](../../figures/meme_multilevel-models.png){fig-align="center"}
:::

## Fixed, random, and mixed effects

::: {.incremental}
- **Fixed effects** refers to what we've done all semester up until now: a common set of parameters in our flat/aggregate model
- **Random effects** refers to what has been introduced with multilevel models so far: a separate intercept and/or slope for each group
- **Mixed effects** refers to the combination of both fixed and random effects
:::

## Fixed, random, and mixed effects {visibility="uncounted"}

- **Fixed effects** refers to what we've done all semester up until now: a common set of parameters in our flat/aggregate model
- **Random effects** refers to what has been introduced with multilevel models so far: a separate intercept and/or slope for each group
- **Mixed effects** refers to the combination of both fixed and random effects

```{python}
#| eval: true
#| echo: false

import numpy as np
import polars as pl
import bambi as bmb

# Set randomization seed
rng = np.random.default_rng(42)

# Specify a function to simulate data
def sim_data(n, betas):
  group = rng.integers(0, 5, size=n)

  x1 = rng.normal(10, 3, size=n)
  x2 = rng.binomial(1, 0.5, size=n)
  x3 = rng.normal(5, 2, size=n)

  X = np.column_stack([np.ones(n), x1, x2, x3])
  prob_y = (np.exp(X @ betas) / (1 + np.exp(X @ betas)))
  y = rng.binomial(1, prob_y, size=n)

  return group, y, x1, x2, x3

# Simulate data
data_arr = sim_data(n = 500, betas = np.array([-0.7, -0.3, -0.5, 0.2]))
data_df = pl.DataFrame(data_arr, schema = ['group', 'y', 'x1', 'x2', 'x3']).to_pandas()
```

```{python}
#| eval: true

ba_model = bmb.Model(
  'y ~ x1 + x2 + x3',
  data = data_df,
  family = 'bernoulli'
)

ba_model
```

## Fixed, random, and mixed effects

```{python}
#| eval: true

ba_model = bmb.Model(
  'y ~ (1 | group) + x1 + x2 + x3',
  data = data_df,
  family = 'bernoulli'
)

ba_model
```

## Fixed, random, and mixed effects

```{python}
#| eval: true

ba_model = bmb.Model(
  'y ~ x1 + x2 + (x3 | group)',
  data = data_df,
  family = 'bernoulli'
)

ba_model
```

## Fixed, random, and mixed effects

```{python}
#| eval: true

ba_model = bmb.Model(
  'y ~ 0 + (1 + x1 + x2 + x3 | group)',
  data = data_df,
  family = 'bernoulli'
)

ba_model
```

# Is there a group structure in your project data? What random effects might make sense to include? {background-color="#006242"}

# Decision-Making Under Uncertainty

## {background-color="#D1CBBD"}

::: {.columns .v-center}
![](../../figures/workflow_all.png){fig-align="center"}
:::

## {background-color="#D1CBBD"}

::: {.columns .v-center}
![](../../figures/workflow_all-decision.png){fig-align="center"}
:::

## Using data to inform decision-making

There are two types of data analysts: **those who know what decision they are informing** and **those who don't**

::: {.incremental}
- A clearly specified objective can be translated into an objective function, typically a **loss function**
- We can use this loss function to **evaluate overall model performance** and select the model that performs best on what matters most
- Since we want to **use data to quantify uncertainty** about the state of the world, using Bayesian statistics to get posterior estimates is optimal
- Frequentist interval estimates and predictive fit **can be useful approximations** (i.e., using `scoring = 'accuracy'` vs. `scoring = 'recall'` when classifying)
:::

## 

::: {.v-center}
![](../../figures/meme_loss-specification.png){fig-align="center"}
:::

## Formalize the objective as a function

:::: {.columns}

::: {.column .gray-box width="92%"}
The objective for the lead qualification program is to maximize time spent along with commissions by minimizing the expected opportunity costs

- For every lead that we don't convert that could have been, we lose $1,000 in unrealized commission
- For every lead that we do convert, we don't lose anything
- For every lead that we try and convert that won't be, we lose a total of $1,500 in wasted time and lost commission

We can use a piecewise linear loss function to represent the asymmetric loss from unrealized vs. wasted commissions
:::

::::

## Formalize the objective as a function {visibility="uncounted"}

:::: {.columns}

::: {.column .gray-box width="92%"}
Instead of relying on **accuracy**, **sensitivity**/**recall**, **specificity**, etc. we can create a custom loss function that directly reflects the business objective

```{python}
#| eval: true
#| echo: false

import numpy as np

conf_matrix = np.array([3562, 2, 46, 11]).reshape(2, 2)
```

```{python}
#| eval: true

def commission_loss(false_positives, false_negatives):
  unrealized = false_negatives * 1000
  wasted = false_positives * 1500
  return unrealized + wasted

commission_loss(
  false_positives = conf_matrix[0, 1],
  false_negatives = conf_matrix[1, 0]
)
```

The model that minimizes this loss function is the best model for the lead qualification problem, with a value we can include in our **executive summary**
:::

::::

## 

![](../../figures/meme_draw-an-owl.png){fig-align="center"}

# After this introduction to regression and machine learning, what are you excited about learning next? {background-color="#006242"}

# Projects

## 

![](../../figures/meme_project-iceberg.png){fig-align="center"}

## Presentation expectations

Use the rubric as a **set of guiding principles** for communicating clearly rather than just a checklist

::: {.incremental}
- Explain the business problem
- Provide an executive summary
- Summarize the data
- Detail the model
- Be professional
:::

## 

:::: {.columns .v-center}

::: {.column width="100%"}
### Our best-performing classification model accurately identifies the leads most likely to be qualified 98.9% of the time and minimizes unrealized or wasted commission at $49,000 {.lato-font}
:::

::::

## Report expectations

Use the rubric as a **set of guiding principles** for communicating clearly rather than just a checklist

::: {.incremental}
- Detail the business objective
- Summarize the data
- Specify the model
- Interpret model results
- Be professional
:::

## Report expectations {visibility="uncounted"}

Structure the report using the modeling workflow, with headings for Plan, Build, Explore, etc.

[**Plan**]{.fragment}

::: {.incremental}
- Describe the business problem
- Detail the ideal data
:::

[**Build**]{.fragment}

::: {.incremental}
- Specify the decision's loss function
- Specify the model's likelihood function, simulate and recover parameters
:::

[**Explore**]{.fragment}

::: {.incremental}
- Exploratory data analysis
- Revise the model specification as needed
:::

## Report expectations {visibility="uncounted"}

[**Reconcile, Fit, and Evaluate**]{.fragment}

[*for model in [Logistic Regression, Ridge Regression, LASSO, Elastic Net, PCR]:*]{.fragment}

::: {.incremental}
- Work through each of the model assumptions when relevant
- Run diagnostics and comment on how well assumptions are met
- Fit the model and tune hyperparameters using cross-valdiation
- Evaluate cross-validated overall model fit
:::

[*Interpret model results from the best-performing model*]{.fragment}

[**Predict**]{.fragment}

::: {.incremental}
- Compute relevant predictions on the test data
- Use this to demosntrate the implications of the model
:::

## {background-color="#006242"}

### Exercise 23 {.lato-font}

1. Choose a concept from the second half of the course to summarize
2. [Create a meme](https://imgflip.com/memegenerator) to illustrate the concept
3. Submit your meme as a PNG on Canvas

## {background-color="#288DC2"}

### Wrap Up {.permanent-marker-font}

#### Summary

- Finished introducing multilevel models
- Summarized decision-making under uncertainty
- Discussed project expectations

#### Next Time

- Project presentations

